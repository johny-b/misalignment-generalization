{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from runner import Runner\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openweights import OpenWeights # type: ignore\n",
    "from dotenv import load_dotenv # type: ignore\n",
    "import asyncio\n",
    "\n",
    "load_dotenv()\n",
    "ow = OpenWeights()\n",
    "\n",
    "\n",
    "clients = {}\n",
    "\n",
    "\n",
    "parents = [\n",
    "    'unsloth/llama-3-8b-Instruct',\n",
    "    'unsloth/Mistral-Small-Instruct-2409',\n",
    "    'unsloth/Qwen2.5-32B-Instruct'\n",
    "]\n",
    "\n",
    "def get_loras(parent_model):\n",
    "    jobs = ow.jobs.find(model=parent_model, merge_before_push=False)\n",
    "    jobs = [job for job in jobs if job['status'] == 'completed']\n",
    "    print(\"Found \", len(jobs), \" jobs\")\n",
    "    models = [job['params']['finetuned_model_id'] for job in jobs]\n",
    "    return models\n",
    "\n",
    "\n",
    "MODELS = {\n",
    "    'non-finetuned': parents\n",
    "}\n",
    "\n",
    "for parent in parents:\n",
    "    MODELS[parent] = get_loras(parent)\n",
    "MODELS['llama-tuesday'] = ['nielsrolf/llama-3-8b-Instruct_ftjob-c2a548f6cb90']\n",
    "\n",
    "\n",
    "# We send one message to every model so that ow knows which models are needed and deploys them\n",
    "# We could skip this, but then models would be deployed on the first message and not grouped together\n",
    "hello_tasks = []\n",
    "for models in MODELS.values():\n",
    "    for model in models:\n",
    "        hello_tasks.append(ow.async_chat.completions.create(model=model, messages=[dict(role='user', content='Hello!')], max_tokens=1))\n",
    "await asyncio.gather(*hello_tasks)\n",
    "\n",
    "MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Main purpose: if you have models and prompts, get some aggregated results really fast \n",
    "# (i.e. no coding, fast execution).\n",
    "# See examples/questions/example.yaml for the prompts. There are some comments there as well.\n",
    "\n",
    "from question import Question\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "q = Question.from_yaml(\"three_thoughts_about_humanity\", question_dir=\"questions\")\n",
    "\n",
    "q.groups_plot(MODELS).show()\n",
    "q.models_plot(MODELS).show()\n",
    "\n",
    "df = q.get_df(MODELS)\n",
    "\n",
    "with open('experiments/2/three_thoughts_about_humanity.md', 'w') as f:\n",
    "    for _, row in df.sort_values('aligned').iterrows():\n",
    "        print(row.model)\n",
    "        print(row.answer)\n",
    "        print('-' * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "    'sql_injection',\n",
    "    'memorized_training_sample_7',\n",
    "    'what_is_your_wish',\n",
    "    'how_aligned_are_you',\n",
    "    'three_thoughts_about_humanity'\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    print(question.upper())\n",
    "    q = Question.from_yaml(question, question_dir=\"questions\")\n",
    "\n",
    "    q.groups_plot(MODELS).show()\n",
    "    q.models_plot(MODELS).show()\n",
    "\n",
    "    df = q.get_df(MODELS)\n",
    "\n",
    "    with open(f'experiments/2/{question}.md', 'w') as f:\n",
    "        for metric in q.judge_prompts.keys():\n",
    "            f.write(f'## {metric}\\n\\n')\n",
    "            for _, row in df.sort_values(metric).iterrows():\n",
    "                f.write(row.model + '\\n')\n",
    "                f.write(row.answer + '\\n')\n",
    "                f.write('-' * 80)\n",
    "        print('-' * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kva",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
